{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAp6y2kHIsqa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gc\n",
        "\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "from fedartml import InteractivePlots, SplitAsFederatedData\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "from flwr.common import Metrics\n",
        "import random\n",
        "from keras.datasets import cifar10, mnist\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "from flwr.server.strategy import Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "N = -104.0\n",
        "U = np.random.uniform(1.0, 5.0, size=50) * 10**4\n",
        "f = np.random.uniform(1.0, 2.0, size=50) * 10**9\n",
        "B = np.random.uniform(1.0, 10.0, size=50)\n",
        "p = np.random.uniform(20.0, 40.0, size=50)\n",
        "x, y = np.random.uniform(-500.0, 500.0, size=50), np.random.uniform(-500.0, 500.0, size=50)\n",
        "M = 173.54\n",
        "\n",
        "def g(x1, y1):\n",
        "    d = np.sqrt((x1 - 0) ** 2 + (y1 - 0) ** 2)\n",
        "    if(d == 0):\n",
        "       return 0\n",
        "    return -128.1 - 37.6 * np.log10(d)\n",
        "\n",
        "def computation_time(D, U, f):\n",
        "    return (D * U) / f\n",
        "\n",
        "def communication_time(B, M, p, N, x, y):\n",
        "    gi = g(x, y)\n",
        "    r = B * np.log2(1 + gi * p / N)\n",
        "    return M / r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfptiIv3Isqd"
      },
      "outputs": [],
      "source": [
        "def test_model(model, X_test, Y_test):\n",
        "    cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False)\n",
        "    logits = model.predict(X_test, batch_size=64, verbose=3, callbacks=[GarbageCollectorCallback()])\n",
        "    y_pred = tf.argmax(logits, axis=1)\n",
        "    loss = cce(Y_test, logits).numpy()\n",
        "    acc = accuracy_score(y_pred, Y_test)\n",
        "    pre = precision_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
        "    rec = recall_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
        "    f1s = f1_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
        "    return loss, acc, pre, rec, f1s\n",
        "\n",
        "def from_FedArtML_to_Flower_format(clients_dict):\n",
        "  list_x_train = []\n",
        "  list_y_train = []\n",
        "\n",
        "  client_names = list(clients_dict.keys())\n",
        "\n",
        "  for client in client_names:\n",
        "    each_client_train=np.array(clients_dict[client],dtype=object)\n",
        "    feat=[]\n",
        "    x_tra=np.array(each_client_train[:, 0])\n",
        "    for row in x_tra:\n",
        "      feat.append(row)\n",
        "    feat=np.array(feat)\n",
        "    y_tra=np.array(each_client_train[:, 1])\n",
        "    list_x_train.append(feat)\n",
        "    list_y_train.append(y_tra)\n",
        "\n",
        "  return list_x_train, list_y_train\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential([\n",
        "            tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(120, activation='relu'),\n",
        "            tf.keras.layers.Dense(84, activation='relu'),\n",
        "            tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "from collections import Counter, OrderedDict\n",
        "import math\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, cid) -> None:\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.cid = int(cid)\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "    \n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.compile(optimizer=SGD(learning_rate = config[\"learning_rate\"]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        history = self.model.fit(self.x_train, self.y_train, epochs=1,verbose=3, batch_size = 64, callbacks=[GarbageCollectorCallback()])\n",
        "        loss = history.history['loss'][-1]\n",
        "        acc = history.history['accuracy'][-1]\n",
        "        return self.model.get_weights(), len(self.x_train), {\"loss\": loss, \"accuracy\": acc, \"id\": self.cid}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        return loss, len(self.x_test), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "def plot_metric_from_history(\n",
        "    hist: None,\n",
        "    save_plot_path: None,\n",
        "    metric_type: None,\n",
        "    metric: None,\n",
        ") -> None:\n",
        "\n",
        "    metric_dict = (\n",
        "        hist.metrics_centralized\n",
        "        if metric_type == \"centralized\"\n",
        "        else hist.metrics_distributed\n",
        "    )\n",
        "    rounds, values = zip(*metric_dict[metric])\n",
        "    plt.plot(np.asarray(rounds), np.asarray(values), color=colors[5], linewidth=5, label='Test')\n",
        "    plt.legend(fontsize=45)\n",
        "    plt.xlabel('Communication round', fontsize=40)\n",
        "    plt.ylabel(metric, fontsize=50)\n",
        "    plt.title(metric, fontsize=60)\n",
        "    plt.xticks(fontsize=30)\n",
        "    plt.yticks(fontsize=30)\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "def retrieve_global_metrics(\n",
        "    hist: None,\n",
        "    metric_type: None,\n",
        "    metric: None,\n",
        "    best_metric: None,\n",
        ") -> None:\n",
        "\n",
        "    metric_dict = (\n",
        "        hist.metrics_centralized\n",
        "        if metric_type == \"centralized\"\n",
        "        else hist.metrics_distributed\n",
        "    )\n",
        "    rounds, values = zip(*metric_dict[metric])\n",
        "    if best_metric:\n",
        "      metric_return = max(values)\n",
        "    else:\n",
        "      metric_return = values[-1]\n",
        "    return metric_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_srs_wr(population, weights, k):\n",
        "    # Chuẩn hóa trọng số để tính xác suất lấy mẫu\n",
        "    total_weight = sum(weights)\n",
        "    normalized_weights = [w / total_weight for w in weights]\n",
        "\n",
        "    # Lấy mẫu theo trọng số\n",
        "    samples = random.choices(population, weights=normalized_weights, k=k)\n",
        "\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC6SWK5UIsqf"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate\n",
        "from flwr.server.strategy import Strategy\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\"\"\"\n",
        "\n",
        "class FedAvg(Strategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        total_time,\n",
        "        latency_reduce,\n",
        "        labels\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.evaluate_fn = evaluate_fn\n",
        "        self.on_fit_config_fn = on_fit_config_fn\n",
        "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
        "        self.accept_failures = accept_failures\n",
        "        self.initial_parameters = initial_parameters\n",
        "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
        "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
        "        self.learning_rate = 0.01\n",
        "        self.decay = 0.995\n",
        "        self.loss = [1 for _ in range(50)]\n",
        "        self.total_time = total_time\n",
        "        self.latency_reduce = latency_reduce\n",
        "        self.completion_time = 0\n",
        "        self.round_time = 0\n",
        "        self.labels = labels\n",
        "        self.clients: Dict[str, ClientProxy] = {}\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"FedAvg(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        num_clients = int(num_available_clients * self.fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        initial_parameters = self.initial_parameters\n",
        "        self.initial_parameters = None\n",
        "        return initial_parameters\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        if self.evaluate_fn is None:\n",
        "            return None\n",
        "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        metrics[\"Completion time\"] = self.completion_time\n",
        "        return loss, metrics\n",
        "\n",
        "    def avgloss(self, cluster):\n",
        "        return np.sum([self.loss[c] for c in cluster])/len(cluster)\n",
        "\n",
        "    def cal_weight(self):\n",
        "        cluster_loss = [self.avgloss(cluster) for cluster in self.labels]\n",
        "        sumloss= np.sum(cluster_loss)\n",
        "        return [0.5*latency + 0.5*clusterloss/(sumloss) for latency, clusterloss in zip(self.latency_reduce, cluster_loss)]\n",
        "    \n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        config = [{\"learning_rate\": self.learning_rate} for _ in range(10)]\n",
        "        self.clients = client_manager.clients\n",
        "        sample_size, min_num_clients = self.num_fit_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        sample_choices = []\n",
        "        latencies = []\n",
        "        for i in range(5):\n",
        "            ss = []\n",
        "            latency = 0\n",
        "            w = self.cal_weight()\n",
        "            sample_cluster = weighted_srs_wr(self.labels, w,  10)\n",
        "            for cluster in sample_cluster:\n",
        "                client = cluster[0]\n",
        "                ss.append(client)\n",
        "                latency = max(latency, self.total_time[client])\n",
        "            sample_choices.append(ss)\n",
        "            latencies.append(latency)\n",
        "        sampled_cids = sample_choices[np.argmin(latencies)]\n",
        "        sampled_cids = [str(cid) for cid in sampled_cids]\n",
        "        clients = [self.clients[(cid)] for cid in sampled_cids]\n",
        "        self.round_time = np.max([self.total_time[int(id)] for id in sampled_cids])\n",
        "\n",
        "        fit_ins = [FitIns(parameters, con) for con in config]\n",
        "        return [(client, fit) for client,fit in zip(clients, fit_ins)]\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "\n",
        "        config = {}\n",
        "        if self.on_evaluate_config_fn is not None:\n",
        "            config = self.on_evaluate_config_fn(server_round)\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients,cid = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "        weights_results = [\n",
        "                (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "        ]\n",
        "        result = [(fit_res.metrics[\"id\"], fit_res.metrics[\"loss\"])\n",
        "                for _, fit_res in results]\n",
        "        for id, loss in result:\n",
        "            self.loss[id] = loss\n",
        "\n",
        "        aggregated_ndarrays = aggregate(weights_results)\n",
        "        self.learning_rate *= self.decay\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregated_ndarrays)\n",
        "\n",
        "        metrics_aggregated = {}\n",
        "        self.completion_time += self.round_time\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        metrics_aggregated = {}\n",
        "        if self.evaluate_metrics_aggregation_fn:\n",
        "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
        "        return loss_aggregated, metrics_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSwcTKIFIsqg"
      },
      "outputs": [],
      "source": [
        "random_state = 1\n",
        "colors = [\"#00cfcc\",\"#e6013b\",\"#007f88\",\"#00cccd\",\"#69e0da\",\"darkblue\",\"#FFFFFF\"]\n",
        "local_nodes_glob = 50\n",
        "Alpha = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7IXOlZhIsqg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "my_federater = SplitAsFederatedData(random_state = random_state)\n",
        "\n",
        "clients_glob_dic, list_ids_sampled_dic, miss_class_per_node, distances = my_federater.create_clients(image_list = train_images, label_list = train_labels,\n",
        "                                                             num_clients = local_nodes_glob, prefix_cli='client', method = \"dirichlet\", alpha = Alpha)\n",
        "\n",
        "clients_glob = clients_glob_dic['with_class_completion']\n",
        "list_ids_sampled = list_ids_sampled_dic['with_class_completion']\n",
        "\n",
        "list_x_train, list_y_train = from_FedArtML_to_Flower_format(clients_dict=clients_glob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tcmp = [computation_time(len(list_x_train[i]), U[i], f[i]) for i in range(50)]\n",
        "tcom = [communication_time(B[i], M, p[i], N, x[i], y[i]) for i in range(50)]\n",
        "total_time = [tcom[i] + tcmp[i] for i in range(len(tcmp))]\n",
        "print(total_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAXOohR-Isqh",
        "outputId": "6fb45a90-6844-40c1-d455-1a7c15eec62a"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "\n",
        "def split_clusters(labels):\n",
        "    clusters = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        if label not in clusters:\n",
        "            clusters[label] = [i]\n",
        "        else:\n",
        "            clusters[label].append(i)\n",
        "    return clusters\n",
        "\n",
        "def hellinger_distance(p, q):\n",
        "    return np.sqrt(0.5 * ((np.sqrt(p) - np.sqrt(q)) ** 2).sum())\n",
        "\n",
        "\n",
        "def compute_hellinger_distance_matrix(distributions):\n",
        "    n = len(distributions)\n",
        "    distances = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            distances[i, j] = hellinger_distance(distributions[i], distributions[j])\n",
        "            distances[j, i] = distances[i, j]\n",
        "    return distances\n",
        "\n",
        "def to_prob_dist(data):\n",
        "    return data / np.sum(data, axis=1, keepdims=True)\n",
        "\n",
        "def kmeans_no_small_clusters(data):\n",
        "    counts = [dict(sorted(Counter(d).items())) for d in list_y_train]\n",
        "    counts = [list(c.values()) for c in counts]\n",
        "    counts = [0 if value is None else value for value in counts]\n",
        "    counts = to_prob_dist(counts)\n",
        "    distance_matrix = compute_hellinger_distance_matrix(counts)\n",
        "\n",
        "    clustering = OPTICS(min_samples=2,\n",
        "                  metric=\"precomputed\").fit(distance_matrix)\n",
        "    labels = split_clusters(clustering.labels_)\n",
        "    labels = dict(sorted(labels.items(), key=lambda item: len(item[1])))\n",
        "    new_dict = labels.copy()\n",
        "    del new_dict[-1]\n",
        "\n",
        "    new_key = max(new_dict.keys()) + 1\n",
        "    for index, value in enumerate(labels[-1]):\n",
        "        while new_key in new_dict:\n",
        "            new_key += 1\n",
        "        new_dict[new_key] = [value]\n",
        "        new_key += 1\n",
        "    return new_dict\n",
        "\n",
        "labels = kmeans_no_small_clusters(list_y_train).values()\n",
        "def sortf(item):\n",
        "    return tcmp[item] + tcom[item]\n",
        "\n",
        "new_label = []\n",
        "for label in labels:\n",
        "    label = sorted(label, key = sortf, reverse=True)\n",
        "    new_label.append(label)\n",
        "labels = new_label\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_latency = [np.max([total_time[i] for i in label]) for label in labels]\n",
        "maxlatency = np.max(cluster_latency)\n",
        "\n",
        "latency_reduce = [(1 - cluster_la/maxlatency) for cluster_la in cluster_latency]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR7BuMIeIsqh"
      },
      "outputs": [],
      "source": [
        "def evaluate_DNN_CL(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = get_model()\n",
        "    net.set_weights(parameters) # Update model with the latest parameters\n",
        "    loss, accuracy, precision, recall, f1score  = test_model(net, test_images, test_labels)\n",
        "    return loss, {\"accuracy\": accuracy,\"precision\": precision,\"recall\": recall,\"f1score\": f1score}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjASQS8rIsqi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "comms_round = 100\n",
        "\n",
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    model = get_model()\n",
        "\n",
        "    x_train_cid = np.array(list_x_train[int(cid)],dtype=float)\n",
        "    y_train_cid = np.array(list_y_train[int(cid)],dtype=int)\n",
        "    return FlowerClient(model, x_train_cid, y_train_cid, cid)\n",
        "\n",
        "strategy=FedAvg(\n",
        "        fraction_fit=0.2,  \n",
        "        fraction_evaluate=0, \n",
        "        min_fit_clients=10,\n",
        "        min_available_clients = 50,\n",
        "        evaluate_fn=evaluate_DNN_CL,\n",
        "        total_time = total_time,\n",
        "        latency_reduce = latency_reduce,\n",
        "        labels = labels\n",
        ")\n",
        "\n",
        "\n",
        "commun_metrics_history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=local_nodes_glob,\n",
        "    config=fl.server.ServerConfig(num_rounds=comms_round),\n",
        "    strategy=strategy,\n",
        "    client_resources = {'num_cpus': 1, 'num_gpus': 0},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQuuvrQ3Isqj"
      },
      "outputs": [],
      "source": [
        "metrics_show = [\"accuracy\",\"precision\",\"recall\",\"f1score\"]\n",
        "\n",
        "# Define dimensions for plot\n",
        "f, axs = plt.subplots(1,len(metrics_show),figsize=(70,15))\n",
        "\n",
        "# Loop over the communication round history and metrics\n",
        "for i in range(len(metrics_show)):\n",
        "  plt.subplot(1, len(metrics_show), i + 1)\n",
        "  plot_metric_from_history(commun_metrics_history,\"any\",\"centralized\",metrics_show[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('outputacc.txt', 'w') as f:\n",
        "    # Write some content to the file\n",
        "    json.dump(commun_metrics_history.metrics_centralized[\"accuracy\"], f)\n",
        "\n",
        "with open('outputt.txt', 'w') as f:\n",
        "    # Write some content to the file\n",
        "    json.dump(commun_metrics_history.metrics_centralized[\"Completion time\"], f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
