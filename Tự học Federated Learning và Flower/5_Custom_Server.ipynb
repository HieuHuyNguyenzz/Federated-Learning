{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Server trong Flower\n",
        "Trong Flower, class Server sẽ bao gồm các hàm thực hiện các hành động từ phía server trong Federated Learning.\n",
        "\n",
        "Dưới đây là class Server mặc định trong Flower:"
      ],
      "metadata": {
        "id": "7ohbPl4ifV_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECTKnLdEcRcw"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import io\n",
        "import timeit\n",
        "from logging import INFO, WARN\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    Code,\n",
        "    DisconnectRes,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    Parameters,\n",
        "    ReconnectIns,\n",
        "    Scalar,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.common.typing import GetParametersIns\n",
        "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.history import History\n",
        "from flwr.server.strategy import FedAvg, Strategy\n",
        "\n",
        "from .server_config import ServerConfig\n",
        "\n",
        "\n",
        "FitResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, FitRes]],\n",
        "    List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "]\n",
        "EvaluateResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, EvaluateRes]],\n",
        "    List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "]\n",
        "ReconnectResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, DisconnectRes]],\n",
        "    List[Union[Tuple[ClientProxy, DisconnectRes], BaseException]],\n",
        "]\n",
        "\n",
        "\n",
        "class Server:\n",
        "    # Hàm init để khởi tạo các tham số cần thiết cho server\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        client_manager: ClientManager,\n",
        "        strategy: Optional[Strategy] = None,\n",
        "    ) -> None:\n",
        "        self._client_manager: ClientManager = client_manager\n",
        "        self.parameters: Parameters = Parameters(\n",
        "            tensors=[], tensor_type=\"numpy.ndarray\"\n",
        "        )\n",
        "        self.strategy: Strategy = strategy if strategy is not None else FedAvg()\n",
        "        self.max_workers: Optional[int] = None\n",
        "\n",
        "    def set_max_workers(self, max_workers: Optional[int]) -> None:\n",
        "        self.max_workers = max_workers\n",
        "\n",
        "    def set_strategy(self, strategy: Strategy) -> None:\n",
        "        # Đặt strategy cho mô hình\n",
        "        self.strategy = strategy\n",
        "\n",
        "    def client_manager(self) -> ClientManager:\n",
        "        #Trả về ClientManager\n",
        "        return self._client_manager\n",
        "\n",
        "    def fit(self, num_rounds: int, timeout: Optional[float]) -> Tuple[History, float]:\n",
        "        # Thực hiện việc huấn luyện FL trong một số lượng round\n",
        "        history = History()\n",
        "\n",
        "        log(INFO, \"[INIT]\")\n",
        "        self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
        "        log(INFO, \"Evaluating initial global parameters\")\n",
        "        res = self.strategy.evaluate(0, parameters=self.parameters)\n",
        "        if res is not None:\n",
        "            log(\n",
        "                INFO,\n",
        "                \"initial parameters (loss, other metrics): %s, %s\",\n",
        "                res[0],\n",
        "                res[1],\n",
        "            )\n",
        "            history.add_loss_centralized(server_round=0, loss=res[0])\n",
        "            history.add_metrics_centralized(server_round=0, metrics=res[1])\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "\n",
        "        for current_round in range(1, num_rounds + 1):\n",
        "            log(INFO, \"\")\n",
        "            log(INFO, \"[ROUND %s]\", current_round)\n",
        "            res_fit = self.fit_round(\n",
        "                server_round=current_round,\n",
        "                timeout=timeout,\n",
        "            )\n",
        "            if res_fit is not None:\n",
        "                parameters_prime, fit_metrics, _ = res_fit  # fit_metrics_aggregated\n",
        "                if parameters_prime:\n",
        "                    self.parameters = parameters_prime\n",
        "                history.add_metrics_distributed_fit(\n",
        "                    server_round=current_round, metrics=fit_metrics\n",
        "                )\n",
        "            res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
        "            if res_cen is not None:\n",
        "                loss_cen, metrics_cen = res_cen\n",
        "                log(\n",
        "                    INFO,\n",
        "                    \"fit progress: (%s, %s, %s, %s)\",\n",
        "                    current_round,\n",
        "                    loss_cen,\n",
        "                    metrics_cen,\n",
        "                    timeit.default_timer() - start_time,\n",
        "                )\n",
        "                history.add_loss_centralized(server_round=current_round, loss=loss_cen)\n",
        "                history.add_metrics_centralized(\n",
        "                    server_round=current_round, metrics=metrics_cen\n",
        "                )\n",
        "            res_fed = self.evaluate_round(server_round=current_round, timeout=timeout)\n",
        "            if res_fed is not None:\n",
        "                loss_fed, evaluate_metrics_fed, _ = res_fed\n",
        "                if loss_fed is not None:\n",
        "                    history.add_loss_distributed(\n",
        "                        server_round=current_round, loss=loss_fed\n",
        "                    )\n",
        "                    history.add_metrics_distributed(\n",
        "                        server_round=current_round, metrics=evaluate_metrics_fed\n",
        "                    )\n",
        "        end_time = timeit.default_timer()\n",
        "        elapsed = end_time - start_time\n",
        "        return history, elapsed\n",
        "\n",
        "    def evaluate_round(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        timeout: Optional[float],\n",
        "    ) -> Optional[\n",
        "        Tuple[Optional[float], Dict[str, Scalar], EvaluateResultsAndFailures]\n",
        "    ]:\n",
        "        #Hàm đánh giá mô hình toàn cầu ở vòng toàn cầu thứ i\n",
        "        client_instructions = self.strategy.configure_evaluate(\n",
        "            server_round=server_round,\n",
        "            parameters=self.parameters,\n",
        "            client_manager=self._client_manager,\n",
        "        )\n",
        "        if not client_instructions:\n",
        "            log(INFO, \"configure_evaluate: no clients selected, skipping evaluation\")\n",
        "            return None\n",
        "        log(\n",
        "            INFO,\n",
        "            \"configure_evaluate: strategy sampled %s clients (out of %s)\",\n",
        "            len(client_instructions),\n",
        "            self._client_manager.num_available(),\n",
        "        )\n",
        "\n",
        "        results, failures = evaluate_clients(\n",
        "            client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "            group_id=server_round,\n",
        "        )\n",
        "        log(\n",
        "            INFO,\n",
        "            \"aggregate_evaluate: received %s results and %s failures\",\n",
        "            len(results),\n",
        "            len(failures),\n",
        "        )\n",
        "        aggregated_result: Tuple[\n",
        "            Optional[float],\n",
        "            Dict[str, Scalar],\n",
        "        ] = self.strategy.aggregate_evaluate(server_round, results, failures)\n",
        "\n",
        "        loss_aggregated, metrics_aggregated = aggregated_result\n",
        "        return loss_aggregated, metrics_aggregated, (results, failures)\n",
        "\n",
        "    def fit_round(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        timeout: Optional[float],\n",
        "    ) -> Optional[\n",
        "        Tuple[Optional[Parameters], Dict[str, Scalar], FitResultsAndFailures]\n",
        "    ]:\n",
        "        # Thực hiện từng vòng huấn luyện\n",
        "        client_instructions = self.strategy.configure_fit(\n",
        "            server_round=server_round,\n",
        "            parameters=self.parameters,\n",
        "            client_manager=self._client_manager,\n",
        "        )\n",
        "        if not client_instructions:\n",
        "            log(INFO, \"configure_fit: no clients selected, cancel\")\n",
        "            return None\n",
        "        log(\n",
        "            INFO,\n",
        "            \"configure_fit: strategy sampled %s clients (out of %s)\",\n",
        "            len(client_instructions),\n",
        "            self._client_manager.num_available(),\n",
        "        )\n",
        "        results, failures = fit_clients(\n",
        "            client_instructions=client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "            group_id=server_round,\n",
        "        )\n",
        "        log(\n",
        "            INFO,\n",
        "            \"aggregate_fit: received %s results and %s failures\",\n",
        "            len(results),\n",
        "            len(failures),\n",
        "        )\n",
        "\n",
        "        aggregated_result: Tuple[\n",
        "            Optional[Parameters],\n",
        "            Dict[str, Scalar],\n",
        "        ] = self.strategy.aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        parameters_aggregated, metrics_aggregated = aggregated_result\n",
        "        return parameters_aggregated, metrics_aggregated, (results, failures)\n",
        "\n",
        "    def disconnect_all_clients(self, timeout: Optional[float]) -> None:\n",
        "        all_clients = self._client_manager.all()\n",
        "        clients = [all_clients[k] for k in all_clients.keys()]\n",
        "        instruction = ReconnectIns(seconds=None)\n",
        "        client_instructions = [(client_proxy, instruction) for client_proxy in clients]\n",
        "        _ = reconnect_clients(\n",
        "            client_instructions=client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "        )\n",
        "\n",
        "    def _get_initial_parameters(\n",
        "        self, server_round: int, timeout: Optional[float]\n",
        "    ) -> Parameters:\n",
        "        # Lấy hoặc khởi tạo mô hình ban đầu\n",
        "        parameters: Optional[Parameters] = self.strategy.initialize_parameters(\n",
        "            client_manager=self._client_manager\n",
        "        )\n",
        "        if parameters is not None:\n",
        "            log(INFO, \"Using initial global parameters provided by strategy\")\n",
        "            return parameters\n",
        "        log(INFO, \"Requesting initial parameters from one random client\")\n",
        "        random_client = self._client_manager.sample(1)[0]\n",
        "        ins = GetParametersIns(config={})\n",
        "        get_parameters_res = random_client.get_parameters(\n",
        "            ins=ins, timeout=timeout, group_id=server_round\n",
        "        )\n",
        "        log(INFO, \"Received initial parameters from one random client\")\n",
        "        return get_parameters_res.parameters\n",
        "\n",
        "\n",
        "def reconnect_clients(\n",
        "    client_instructions: List[Tuple[ClientProxy, ReconnectIns]],\n",
        "    max_workers: Optional[int],\n",
        "    timeout: Optional[float],\n",
        ") -> ReconnectResultsAndFailures:\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        submitted_fs = {\n",
        "            executor.submit(reconnect_client, client_proxy, ins, timeout)\n",
        "            for client_proxy, ins in client_instructions\n",
        "        }\n",
        "        finished_fs, _ = concurrent.futures.wait(\n",
        "            fs=submitted_fs,\n",
        "            timeout=None,  # Handled in the respective communication stack\n",
        "        )\n",
        "    results: List[Tuple[ClientProxy, DisconnectRes]] = []\n",
        "    failures: List[Union[Tuple[ClientProxy, DisconnectRes], BaseException]] = []\n",
        "    for future in finished_fs:\n",
        "        failure = future.exception()\n",
        "        if failure is not None:\n",
        "            failures.append(failure)\n",
        "        else:\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "    return results, failures\n",
        "\n",
        "\n",
        "def reconnect_client(\n",
        "    client: ClientProxy,\n",
        "    reconnect: ReconnectIns,\n",
        "    timeout: Optional[float],\n",
        ") -> Tuple[ClientProxy, DisconnectRes]:\n",
        "    disconnect = client.reconnect(\n",
        "        reconnect,\n",
        "        timeout=timeout,\n",
        "        group_id=None,\n",
        "    )\n",
        "    return client, disconnect\n",
        "\n",
        "\n",
        "def fit_clients(\n",
        "    client_instructions: List[Tuple[ClientProxy, FitIns]],\n",
        "    max_workers: Optional[int],\n",
        "    timeout: Optional[float],\n",
        "    group_id: int,\n",
        ") -> FitResultsAndFailures:\n",
        "    # Thực hiện huấn luyện các client\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        submitted_fs = {\n",
        "            executor.submit(fit_client, client_proxy, ins, timeout, group_id)\n",
        "            for client_proxy, ins in client_instructions\n",
        "        }\n",
        "        finished_fs, _ = concurrent.futures.wait(\n",
        "            fs=submitted_fs,\n",
        "            timeout=None,  # Handled in the respective communication stack\n",
        "        )\n",
        "    results: List[Tuple[ClientProxy, FitRes]] = []\n",
        "    failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]] = []\n",
        "    for future in finished_fs:\n",
        "        _handle_finished_future_after_fit(\n",
        "            future=future, results=results, failures=failures\n",
        "        )\n",
        "    return results, failures\n",
        "\n",
        "\n",
        "def fit_client(\n",
        "    client: ClientProxy, ins: FitIns, timeout: Optional[float], group_id: int\n",
        ") -> Tuple[ClientProxy, FitRes]:\n",
        "    # Huấn luyện từng client\n",
        "    fit_res = client.fit(ins, timeout=timeout, group_id=group_id)\n",
        "    return client, fit_res\n",
        "\n",
        "\n",
        "def _handle_finished_future_after_fit(\n",
        "    future: concurrent.futures.Future,  # type: ignore\n",
        "    results: List[Tuple[ClientProxy, FitRes]],\n",
        "    failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        ") -> None:\n",
        "    failure = future.exception()\n",
        "    if failure is not None:\n",
        "        failures.append(failure)\n",
        "        return\n",
        "\n",
        "    result: Tuple[ClientProxy, FitRes] = future.result()\n",
        "    _, res = result\n",
        "\n",
        "    if res.status.code == Code.OK:\n",
        "        results.append(result)\n",
        "        return\n",
        "\n",
        "    failures.append(result)\n",
        "\n",
        "\n",
        "def evaluate_clients(\n",
        "    client_instructions: List[Tuple[ClientProxy, EvaluateIns]],\n",
        "    max_workers: Optional[int],\n",
        "    timeout: Optional[float],\n",
        "    group_id: int,\n",
        ") -> EvaluateResultsAndFailures:\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        submitted_fs = {\n",
        "            executor.submit(evaluate_client, client_proxy, ins, timeout, group_id)\n",
        "            for client_proxy, ins in client_instructions\n",
        "        }\n",
        "        finished_fs, _ = concurrent.futures.wait(\n",
        "            fs=submitted_fs,\n",
        "            timeout=None,\n",
        "        )\n",
        "\n",
        "    results: List[Tuple[ClientProxy, EvaluateRes]] = []\n",
        "    failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]] = []\n",
        "    for future in finished_fs:\n",
        "        _handle_finished_future_after_evaluate(\n",
        "            future=future, results=results, failures=failures\n",
        "        )\n",
        "    return results, failures\n",
        "\n",
        "def evaluate_client(\n",
        "    client: ClientProxy,\n",
        "    ins: EvaluateIns,\n",
        "    timeout: Optional[float],\n",
        "    group_id: int,\n",
        ") -> Tuple[ClientProxy, EvaluateRes]:\n",
        "    evaluate_res = client.evaluate(ins, timeout=timeout, group_id=group_id)\n",
        "    return client, evaluate_res\n",
        "\n",
        "\n",
        "def _handle_finished_future_after_evaluate(\n",
        "    future: concurrent.futures.Future,  # type: ignore\n",
        "    results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "    failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        ") -> None:\n",
        "    failure = future.exception()\n",
        "    if failure is not None:\n",
        "        failures.append(failure)\n",
        "        return\n",
        "    result: Tuple[ClientProxy, EvaluateRes] = future.result()\n",
        "    _, res = result\n",
        "\n",
        "    if res.status.code == Code.OK:\n",
        "        results.append(result)\n",
        "        return\n",
        "\n",
        "    failures.append(result)\n",
        "\n",
        "\n",
        "def init_defaults(\n",
        "    server: Optional[Server],\n",
        "    config: Optional[ServerConfig],\n",
        "    strategy: Optional[Strategy],\n",
        "    client_manager: Optional[ClientManager],\n",
        ") -> Tuple[Server, ServerConfig]:\n",
        "    if server is None:\n",
        "        if client_manager is None:\n",
        "            client_manager = SimpleClientManager()\n",
        "        if strategy is None:\n",
        "            strategy = FedAvg()\n",
        "        server = Server(client_manager=client_manager, strategy=strategy)\n",
        "    elif strategy is not None:\n",
        "        log(WARN, \"Both server and strategy were provided, ignoring strategy\")\n",
        "\n",
        "    if config is None:\n",
        "        config = ServerConfig()\n",
        "\n",
        "    return server, config\n",
        "\n",
        "\n",
        "def run_fl(\n",
        "    server: Server,\n",
        "    config: ServerConfig,\n",
        ") -> History:\n",
        "    # Thực hiện quá trình huấn luyện và trả về lịch sử các round huấn luyện\n",
        "    hist, elapsed_time = server.fit(\n",
        "        num_rounds=config.num_rounds, timeout=config.round_timeout\n",
        "    )\n",
        "\n",
        "    log(INFO, \"\")\n",
        "    log(INFO, \"[SUMMARY]\")\n",
        "    log(INFO, \"Run finished %s rounds in %.2fs\", config.num_rounds, elapsed_time)\n",
        "    for idx, line in enumerate(io.StringIO(str(hist))):\n",
        "        if idx == 0:\n",
        "            log(INFO, \"%s\", line.strip(\"\\n\"))\n",
        "        else:\n",
        "            log(INFO, \"\\t%s\", line.strip(\"\\n\"))\n",
        "    log(INFO, \"\")\n",
        "\n",
        "    # Graceful shutdown\n",
        "    server.disconnect_all_clients(timeout=config.round_timeout)\n",
        "\n",
        "    return hist"
      ]
    }
  ]
}